
\chapter{Introduction}
\section{Background and Motivation}\label{sec:intro:background}
NP-hard combinatorial optimisation problems are, well, hard to solve, and generally
don't allow for as athestetically pleasing solutions as polynomially solvable problems.
Commonly, they are reformulated as \gls{ilp} problems, and solved applying general purpose
\gls{mip} solvers backed with a bouquet of user callbacks for supplying
stronger lower bounds and good incumbents.

Hence, there exists a whole class of problems which, at least superfiscially, are
solved in the same manner.

\paragraph{Collecting Prize}
There exists a family of combinatorial optimisation problems in graphs which involve
finding a subgraph which optimises the trade-off of including a vertex for its prize
(or to avoid paying a penalty) and paying the cost of the edge(s) needed to connect
to it.

These problems generally come with the moniker of \textit{Prize-Collecting}
and were first introduced by \citet*{balas1989prize}
with the introduction of the \textit{\gls{pctsp}}. This problem is a generalisation of
the famous \gls{tsp}, relaxing its Hamiltonian tour constraint by instead applying penalities
to missed vertices and setting a minimum on collected ``prize''.

Perhaps unsurprisingly, this concept of collecting prize spread to another famous optimisation
problem, that is the \gls{stp}. This was done by \citet{Bienstock1993} in conjuction with
defining an approximation algorithm for the \gls{pctsp}. This variant of the \gls{stp},
aptly named the \gls{pcstp}, gained traction --- particularly with the
\textit{11th DIMACS Implementation Challenge}\citep{DIMACS}.

At the onset of writing this thesis, we started off with the stated
goal of surveying research done
on the \gls{pcstp}, and attempting to fill out any holes with methods defined for the older
\gls{pctsp}. This was considered with the assumption that the older problem had
been more covered.
However, it turned out that the \gls{pcstp} had been \textit{far} more covered
by research with multiple exact algorithms
\citep{ljubic2005solving, leitner2016dual, gamrath2017scip},
approximation algorithms \citep{Bienstock1993,goemans1995general,Johnson:2000:PCS:338219.338637},
and primal heuristics \citep{canuto2001local,fu2014knowledge,akhmedov2016divide}
having been already proposed while the \gls{pctsp} had received little such attention
\citep{archetti2014chapter}.

Still wanting to have the \gls{pcstp} as our starting point, we decided to still survery the
problem with the hope that any knowledge gained could be applied somehow. We found an application
for this when running into the \gls{mtp}. The \gls{mtp} is a generalisation of the \gls{pcstp}
which, to the best of our knowledge, has not been explored in the general case. Thus we set out
to apply knowledge from the \gls{pcstp} to the \gls{mtp} to hopefully learn something about
both problems.
\section{Aim and Scope}
This thesis is split in two parts which examine the same problem area with different lenses.
\paragraph{Part I}

In the first part, we perform a
survey of the \acrlong{pctsp} where we report, detail, and bring intution to the most interesting
and/or effective methods for solving the \gls{pcstp}.
Our goal is not for this to be a comprehensive index
of research done on the \gls{pcstp}, but to give a comprehensive \textit{overview} of
types of methods are used to solve the \gls{pcstp}. For example, we won't fully detail \textit{all}
heuristics or approximation algorithms for the \gls{pcstp}, but the ones we find the most interesting.

The reader should be left with a good understanding of
what constitutes a state-of-the-art method for solving the \gls{pcstp}.

\paragraph{Part II}

In the second part, we widen our lenses and look at problems which are related to the \gls{pcstp},
but still from the perspective of
the \gls{pcstp}.
First we will take a superficial look at the closest problem,
before taking a deep dive in the \acrlong{mtp} for which
we proprose an \gls{ilp} formulation, a new dataset, and a solver.

Our aim is to uncover how the \gls{pcstp} relates to other problems
both with regards to the nature of the problems themselves and state of
research.

Futhermore, we wish to examine how translatable results made for the \gls{pcstp} for similar problems.
Can research on one combinatorial optimisation problem be applied directly or maybe just serve as a
starting point for another such problem?

\medskip\noindent
Overall, we first take a look at a well-understood problem with a mature field of reasearch and collect
the main points of knowledge in one place. Then we turn our view to problems with younger research fields
and see how the former relates to the latter.

In the end, we aim to see how well state-of-the-art methods used to solve an NP-hard combinatorial
optimisation problem can be utilised another NP-hard problem when the problems are similar in
formulation.

\section{Related Work}
Besides the work we relay in Part~\ref{part:survey} of this thesis,
there has been some recent work which is closely related
 to what we present. Particularly, there has been some in surveying the
\acrlong{pcstp} from different angles.

\citet*{rehfeldt2016reduction} present a comprehensive study of all preprocessing routines
for the \gls{pcstp} and the Node-Weighted Steiner Tree Problem. This is similar in scope to
Section~\ref{sec:solving:pre} in this thesis. The reader is encouraged to visit their paper
if they wish to see a more theoretical and comprehensive look at preprocessing routines for
the \gls{pcstp}. We aim to complement this with a slightly more ituitive description of the
routines.

\citet*{sun2018classical} presents a survey of the practical applications of the \gls{pcstp}.
In their thesis, they first perform a short and sweet summary on the historical perspective of
solving the \gls{pcstp}. Their main constribution, however,
is a detailed look at the applications
of the problem in real world scenarios.

\section{Notation}\label{sec:intro:notation}

Throughout this thesis, we will make repeated use of some shorthand notation, particularly
with respect to graphs and decisions vectors.

\paragraph{Graphs}

We define the adjacency function $\delta : V \to \mathcal{P} (E)$ on undirected graphs as
the function which given the index of a vertex, returns all adjacent edges, that is
$$\delta(i) = \{(i,j) \mid j \in V \wedge (i, j) \in E\}\mathnormal{.}$$
On a directed graph, this is replaced by two functions
$\delta^+ : V \to \mathcal{P} (A)$
and $\delta^-: V \to \mathcal{P} (A)$.
The former returns all vertices, $j$, for which there exists an arc
which starts in the input vertex, $i$, and terminates in $j$, that is
$$\delta^+(i) = \{(i, j) \mid j \in V \wedge (i, j) \in A\}\mathnormal{.}$$
Correspondingly, $\delta^-$ then returns the set,
$$\delta^-(i) = \{(j, i) \mid j \in V \wedge (j, i) \in A\}\mathnormal{.}$$
When we are not interested in adjacent edges, but instead neighbouring vertices,
we may use $\delta(v)$ to mean the set of vertices which are neighbours to $v$.
This will be clear in usage.


When given some subset of vertices, $S \subseteq V$, as input,
$\delta(S)$ returns all edges which span the cut $(S, V \setminus S)$.
Thus we have $\delta : \mathcal{P}(V) \to \mathcal{P}(E)$, with
$$\delta(S) = \{(i,j) \in E \mid i \in S \wedge j \in V \setminus S\}\mathnormal{.}$$
And for directed graphs we have, $\delta^+ : \mathcal{P}(V) \to \mathcal{P}(A)$, with
$$\delta^+(S) = \{(i,j) \in A \mid i \in S \wedge j \in V \setminus S\}\mathnormal{,}$$
and $\delta^- : \mathcal{P}(V) \to \mathcal{P}(A)$, with
$$\delta^-(S) = \{(i,j) \in A \mid i \in V \setminus S \wedge j \in S\}\mathnormal{.}$$

\paragraph{Decision Vectors}

When working with \gls{ilp} models of graph problems, we often need to sum over variables
related to edges or vertices. For example, let $x_{ij}$ be $1$ if the edge $(i,j) \in E$
is part of a solution and $0$ if not, and let $L \subseteq E$ be some subset of edges.
Then the \textit{function} $x : \mathcal{P} (E) \to \NN$ returns the number of edges
 in $L$ which was selected in the solution defined by $x$,
 $$x(L) = \sum_{(i, j) \in L} x_{ij}\mathnormal{.}$$
 If $x_{ij}$ is a real number, then $x(L)$ returns a real number as well.

%%% Local Variables:
%%% TeX-master: "report"
%%% reftex-default-bibliography: ("lit.bib")
%%% End: