\chapter{Introduction}
\section{Background and Motivation}\label{sec:intro:background}
The hardest problems to solve do not necessarily have the most aethstetically pleasing solutions.
This is particularly true within the realm of NP-hard combinatorial optimisation problems.
Commonly, these are reformulated as \gls{ilp} problems, and solved through
branch-and-bound
by applying general purpose
\gls{mip} solvers. These solvers are then typically
fed with a bouquet of user callbacks for supplying
stronger lower bounds and good incumbents.

This is much akin to working with small disjoint building blocks
within a fixed framework, and when the problem changes, the framework stays
the same. Sometimes even some of the building blocks stay the same.

Hence, for many of these kinds of problems, finding exact solutions
involve using the same frameworks again and again.
Thus there exists a whole class of problems which are, to some point,
solved in the same manner.

\paragraph{Collecting Prize}
There is a family of combinatorial optimisation problems which involve
finding a subgraph which minimises total edge cost while paying a penalty
for not including vertices.

These problems generally live under the moniker of \textit{Prize-Collecting}
and were first introduced by \citet*{balas1989prize}
with the introduction of the \textit{\gls{pctsp}}. This problem is a generalisation of
the famous \gls{tsp}, relaxing its Hamiltonian tour constraint by instead applying penalities
to missed vertices and setting a minimum on collected \textit{prize}.

Perhaps unsurprisingly, this concept of collecting prize spread to another famous optimisation
problem, that is the \gls{stp}. This was done by \citet{Bienstock1993} in conjuction with
defining an approximation algorithm for the \gls{pctsp}. This variant of the \gls{stp},
aptly named the \gls{pcstp}, gained traction --- particularly with the
\textit{11th DIMACS Implementation Challenge} having Steiner Trees as its subject
\citep{DIMACS}.

At the onset of writing this thesis, the stated goal was to
survey the research done
on the \gls{pcstp}, and attempt to fill out any holes found with methods defined for the older
\gls{pctsp}. This was considered with the assumption that the older problem had
been more covered.
However, it turned out that the \gls{pcstp} had been far more covered
by research with multiple exact algorithms
\citep{ljubic2005solving, leitner2016dual, gamrath2017scip},
approximation algorithms \citep{Bienstock1993,goemans1995general,Johnson:2000:PCS:338219.338637},
and primal heuristics \citep{canuto2001local,fu2014knowledge,akhmedov2016divide}
having been already proposed while the \gls{pctsp} had received little such attention
\citep{archetti2014chapter}.

As a consequence, the \gls{pcstp} with its mature field of research then appears to be a strong
starting point. The obvious choice, then, is to flip the equation and apply what we learn
from the \gls{pcstp} to the \gls{pctsp}.
However, there is another interesting problem to explore: \textit{the \gls{mtp}}.
The \gls{mtp} is a generalisation of the \gls{pcstp}
which involves finding the subgraph which minimises total edge cost summed with an
\textit{assignment cost} for assigning each vertex in the input graph to a vertex in
the subgraph. Hence, while the \gls{pctsp} is similar to the \gls{pcstp} by sharing
its objective functon, the \gls{mtp} instead shares solution shape with the \gls{pcstp}.

Additionally, the \gls{mtp} has yet to receive much attention
besides the special case where the input graph is
a tree, giving us plenty of space to work in. All in all, based on the evaluation
that the tour constraint of \gls{pctsp}
puts it at a further distance to the \gls{pcstp}, we make the \gls{mtp}
the secondary target of this thesis.
\section{Aim and Scope}
As we touch upon two slightly disjoint subjects, this thesis is split
in two parts.
\paragraph{Part I}

In the first part, we perform a
survey of the \acrlong{pctsp} where we report, detail, and bring intution to the most interesting
and/or effective methods for solving the \gls{pcstp}.
Our goal is not for this to be a comprehensive retelling
of all research done on the \gls{pcstp}, but to give a comprehensive overview of
the kind of methods which are used to solve the \gls{pcstp}.
For example, we will not fully detail all
heuristics or approximation algorithms for the \gls{pcstp},
but select those that we find most interesting or important.

The reader should be left with a good understanding of
what constitutes a state-of-the-art method for solving the \gls{pcstp}.

\paragraph{Part II}

In the second part, we widen our lenses and look at problems which are related to the \gls{pcstp},
but still from the perspective of
the \gls{pcstp}.
First we will take a superficial look at the closest problem,
before taking a deep dive in the \acrlong{mtp} for which
we proprose an \gls{ilp} formulation, a new dataset, and a solver.

Our aim is to uncover how the \gls{pcstp} relates to other problems
both with regards to the nature of the problems themselves and state of
research.

Furthermore, we wish to examine how translatable results made for the \gls{pcstp} are for similar problems.
In other words, we ask the question:
``Can research on one combinatorial optimisation problem be applied directly, or at least
serve as a good starting point for solutions to another such problem?''

\medskip\noindent
Overall, we first take a look at a well-understood problem with a mature field of reasearch and collect
the main points of knowledge in one place. Then we turn our view to problems with younger research fields
and see how the former relates to the latter.

In the end, we aim to see how well state-of-the-art methods used to solve an NP-hard combinatorial
optimisation problem can be utilised to solver another NP-hard problem when the problems are particularly
similar in formulation.

\section{Related Work}
Besides the research we cover through our survey in
Part~\ref{part:survey} of this thesis,
there has been some recent work which is closely related
 to what we present. Particularly, there has been some in surveying the
\acrlong{pcstp} from different angles.

\citet*{rehfeldt2016reduction} present a comprehensive study of all preprocessing routines
for the \gls{pcstp} and the Node-Weighted Steiner Tree Problem. This is similar in scope to
Section~\ref{sec:solving:pre} in this thesis. The reader is encouraged to visit their paper
if they wish to see a more theoretical and comprehensive look at preprocessing routines for
the \gls{pcstp}. We aim to complement this with a slightly more intuitive description of the
routines.

\citet*{sun2018classical} presents a survey of the practical applications of the \gls{pcstp}.
In their thesis, they first perform a short summary of the historical perspective of
solving the \gls{pcstp}. Their main contributions include
a detailed look at the applications
of the problem in real world scenarios.

\section{Notation}\label{sec:intro:notation}

Throughout this thesis, we will make repeated use of some shorthand notation, particularly
with respect to graphs and decisions vectors.

\paragraph{Graphs}

We define the adjacency function $\delta : V \to \mathcal{P} (E)$ on undirected graphs as
the function which given the index of a vertex, returns all adjacent edges, that is
\[\delta(i) = \{(i,j) \mid j \in V \wedge (i, j) \in E\}\mathnormal{.}\]
On a directed graph, this is replaced by two functions
$\delta^+ : V \to \mathcal{P} (A)$
and $\delta^-: V \to \mathcal{P} (A)$.
The former returns all vertices, $j$, for which there exists an arc
which starts in the input vertex, $i$, and terminates in $j$, that is
\[\delta^+(i) = \{(i, j) \mid j \in V \wedge (i, j) \in A\}\mathnormal{.}\]
Correspondingly, $\delta^-$ then returns the set,
\[\delta^-(i) = \{(j, i) \mid j \in V \wedge (j, i) \in A\}\mathnormal{.}\]
When we are not interested in adjacent edges, but instead neighbouring vertices,
we may use $\delta(v)$ to mean the set of vertices which are neighbours to $v$.
This will be clear in usage.


When given some subset of vertices, $S \subseteq V$, as input,
$\delta(S)$ returns all edges which span the cut $(S, V \setminus S)$.
Thus we have $\delta : \mathcal{P}(V) \to \mathcal{P}(E)$, with
\[\delta(S) = \{(i,j) \in E \mid i \in S \wedge j \in V \setminus S\}\mathnormal{.}\]
And for directed graphs we have, $\delta^+ : \mathcal{P}(V) \to \mathcal{P}(A)$, with
\[\delta^+(S) = \{(i,j) \in A \mid i \in S \wedge j \in V \setminus S\}\mathnormal{,}\]
and $\delta^- : \mathcal{P}(V) \to \mathcal{P}(A)$, with
\[\delta^-(S) = \{(i,j) \in A \mid i \in V \setminus S \wedge j \in S\}\mathnormal{.}\]

\paragraph{Decision Vectors}

When working with \gls{ilp} models of graph problems, we often need to sum over variables
related to edges or vertices. For example, let $x_{ij}$ be $1$ if the edge $(i,j) \in E$
is part of a solution and $0$ if not, and let $L \subseteq E$ be some subset of edges.
Then the \textit{function} $x : \mathcal{P} (E) \to \NN$ returns the number of edges
 in $L$ which was selected in the solution defined by $x$,
 \[x(L) = \sum_{(i, j) \in L} x_{ij}\mathnormal{.}\]
 If $x_{ij}$ is a real number, then $x(L)$ returns a real number as well.

\clearpage
\glsaddall
\printglossaries

%%% Local Variables:
%%% TeX-master: "report"
%%% reftex-default-bibliography: ("lit.bib")
%%% End:
